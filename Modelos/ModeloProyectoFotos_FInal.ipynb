{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creación del modelo"
      ],
      "metadata": {
        "id": "LrvNxP0SvUrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación de dependencias\n",
        "!pip install -q kagglehub tabulate matplotlib scikit-learn seaborn"
      ],
      "metadata": {
        "id": "fM9iHqz3stkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recolección de las imagenes"
      ],
      "metadata": {
        "id": "wWUetwAyvS1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub, os, random, shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Descarga y prepara el dataset\n",
        "path = kagglehub.dataset_download(\"frabbisw/facial-age\")\n",
        "original_dir = os.path.join(path, \"face_age\")\n",
        "if not os.path.isdir(original_dir):\n",
        "    original_dir = path\n",
        "\n",
        "random.seed(42)\n",
        "data_dir = \"data\"\n",
        "LABELS = {'<18': range(1,18), '18+': range(18,200)}\n",
        "MAX_PER_CLASS = 10000\n",
        "\n",
        "# Recolectar imágenes\n",
        "all_imgs = []\n",
        "for sub in os.listdir(original_dir):\n",
        "    age_str = sub.rstrip('+')\n",
        "    try:\n",
        "        age = int(age_str)\n",
        "    except ValueError:\n",
        "        continue\n",
        "    label = '<18' if age < 18 else '18+'\n",
        "    folder = os.path.join(original_dir, sub)\n",
        "    for fn in os.listdir(folder):\n",
        "        all_imgs.append((os.path.join(folder, fn), label))\n",
        "\n",
        "# Balancear clases\n",
        "by_label = {'<18': [], '18+': []}\n",
        "for path_img,lab in all_imgs:\n",
        "    by_label[lab].append(path_img)\n",
        "\n",
        "sampled = []\n",
        "for lab, paths in by_label.items():\n",
        "    n = min(len(paths), MAX_PER_CLASS)\n",
        "    sampled += [(p, lab) for p in random.sample(paths, n)]\n",
        "\n",
        "# Split estratificado\n",
        "labels = [lab for _,lab in sampled]\n",
        "train, temp = train_test_split(sampled, test_size=0.30, stratify=labels, random_state=42)\n",
        "labels_temp = [lab for _,lab in temp]\n",
        "val, test  = train_test_split(temp, test_size=0.50, stratify=labels_temp, random_state=42)\n",
        "\n",
        "# Crear carpetas y copiar imágenes\n",
        "for split, dataset in (('train',train), ('val',val), ('test',test)):\n",
        "    for label in ['<18','18+']:\n",
        "        os.makedirs(os.path.join(data_dir, split, label), exist_ok=True)\n",
        "    for src, lab in dataset:\n",
        "        dst = os.path.join(data_dir, split, lab, os.path.basename(src))\n",
        "        if not os.path.exists(dst):\n",
        "            shutil.copy(src, dst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN_950tIvRqV",
        "outputId": "47d0c7df-14c9-4d24-948c-9d26d6eb0f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/frabbisw/facial-age?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 840M/840M [00:08<00:00, 102MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuración y preparación de datos"
      ],
      "metadata": {
        "id": "aYML_Vo-x8uF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "\n",
        "TRAIN_DIR = 'data/train'\n",
        "VAL_DIR = 'data/val'\n",
        "TEST_DIR = 'data/test'\n",
        "\n",
        "train_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.7, 1.3],\n",
        "    zoom_range=0.25,\n",
        "    shear_range=0.18,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "val_test_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_photos = train_gen.flow_from_directory(TRAIN_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')\n",
        "\n",
        "val_photos = val_test_gen.flow_from_directory(VAL_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary', shuffle=False)\n",
        "\n",
        "test_photos = val_test_gen.flow_from_directory(TEST_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary', shuffle=False)\n",
        "\n",
        "#Pesos de clase automáticos\n",
        "counter = Counter(train_photos.classes)\n",
        "total = sum(counter.values())\n",
        "class_weight = {int(i): total/v for i, v in counter.items()}\n",
        "print(f\"Pesos de clase: {class_weight}\")\n",
        "\n",
        "# Función para crear varios modelos de manera automatica\n",
        "def build_cnn_model(base_model_class=MobileNetV2, num_dense=64, dropout1=0.5, dropout2=0.3):\n",
        "    base = base_model_class(input_shape=(*IMG_SIZE,3), include_top=False, weights='imagenet')\n",
        "\n",
        "    base.trainable = True\n",
        "\n",
        "    for layer in base.layers[:-20]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    pool = layers.GlobalAveragePooling2D()(base.output)\n",
        "\n",
        "    normaliz = layers.BatchNormalization()(pool)\n",
        "\n",
        "    dropout = layers.Dropout(dropout1)(normaliz)\n",
        "\n",
        "    dense = layers.Dense(num_dense, activation='relu')(dropout)\n",
        "\n",
        "    normaliz = layers.BatchNormalization()(dense)\n",
        "\n",
        "    dropout = layers.Dropout(dropout2)(normaliz)\n",
        "\n",
        "    output = layers.Dense(1, activation='sigmoid')(dropout)\n",
        "\n",
        "    model = models.Model(base.input, output)\n",
        "\n",
        "    model.compile(optimizer=optimizers.Adam(1e-4),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
        "    return model\n",
        "\n",
        "#Definición de modelos y nombres\n",
        "modelos = [\n",
        "    (MobileNetV2,     \"MobileNetV2\"),\n",
        "    (ResNet50,        \"ResNet50\")\n",
        "]\n",
        "\n",
        "m_path = '/content/modelos'\n",
        "os.makedirs(m_path, exist_ok=True)\n",
        "\n",
        "resultados = []\n",
        "histories = {}\n",
        "thresholds = {}\n",
        "confusions = {}\n",
        "\n",
        "for model_class, model_name in modelos:\n",
        "    print(\"\\n//////////////////////////////////////\")\n",
        "    print(f\"\\n Entrenando modelo: {model_name}\")\n",
        "\n",
        "    es = callbacks.EarlyStopping(monitor='val_auc', patience=8, restore_best_weights=True, mode='max')\n",
        "\n",
        "    mc = callbacks.ModelCheckpoint(\n",
        "        filepath=f\"{m_path}/{model_name}.keras\",\n",
        "        monitor='val_auc',\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # LLamamos a la funcion build_cnn_model\n",
        "    model = build_cnn_model(base_model_class=model_class, num_dense=64, dropout1=0.5, dropout2=0.3)\n",
        "\n",
        "    # Entrenamos al modelo\n",
        "    history = model.fit(\n",
        "        train_photos,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=val_photos,\n",
        "        callbacks=[es, mc],\n",
        "        class_weight=class_weight,\n",
        "        verbose=1\n",
        "    )\n",
        "    histories[model_name] = history\n",
        "\n",
        "    # Evaluación y threshold óptimo\n",
        "    y_true = train_photos.classes\n",
        "    y_pred_proba = model.predict(test_photos).ravel()\n",
        "    fpr, tpr, lista_umbral = roc_curve(y_true, y_pred_proba)\n",
        "    optimal_idx = np.argmax(tpr - fpr)\n",
        "    umbral_optimo = lista_umbral[optimal_idx]\n",
        "    thresholds[model_name] = umbral_optimo\n",
        "\n",
        "    # Guardar threshold\n",
        "    threshold_path = f\"{m_path}/{model_name}_threshold.txt\"\n",
        "    with open(threshold_path, \"w\") as f:\n",
        "        f.write(str(umbral_optimo))\n",
        "    print(f\"Umbral guardado en: {threshold_path}\")\n",
        "\n",
        "    # Métricas y resultados\n",
        "    y_pred = (y_pred_proba >= umbral_optimo).astype(int)\n",
        "    acc = (y_pred == y_true).mean()\n",
        "    auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    precision = tp / (tp + fp) if tp+fp > 0 else 0\n",
        "    recall = tp / (tp + fn) if tp+fn > 0 else 0\n",
        "    resultados.append({\n",
        "        \"Modelo\": model_name,\n",
        "        \"Accuracy\": round(acc,4),\n",
        "        \"AUC\": round(auc,4),\n",
        "        \"Precision\": round(precision,4),\n",
        "        \"Recall\": round(recall,4),\n",
        "        \"Threshold\": round(umbral_optimo, 3)\n",
        "    })\n",
        "    confusions[model_name] = confusion_matrix(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOxvfk1as0Ef",
        "outputId": "00b242d0-441f-4b62-f429-99f959a2ccf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6844 images belonging to 2 classes.\n",
            "Found 1467 images belonging to 2 classes.\n",
            "Found 1467 images belonging to 2 classes.\n",
            "Pesos de clase: {0: 1.6704906028801563, 1: 2.4914452129595923}\n",
            "\n",
            "//////////////////////////////////////\n",
            "\n",
            " Entrenando modelo: MobileNetV2\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7423 - auc: 0.8218 - loss: 1.1006\n",
            "Epoch 1: val_auc improved from -inf to 0.93579, saving model to /content/modelos/MobileNetV2.keras\n",
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 2s/step - accuracy: 0.7426 - auc: 0.8221 - loss: 1.0996 - val_accuracy: 0.8439 - val_auc: 0.9358 - val_loss: 0.3693\n",
            "Epoch 2/30\n",
            "\u001b[1m158/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:51\u001b[0m 2s/step - accuracy: 0.8611 - auc: 0.9350 - loss: 0.6727"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gráficas"
      ],
      "metadata": {
        "id": "ThLOffCZvFWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(resultados)\n",
        "\n",
        "# Gráfica de barras de Accuracy, AUC, Precision, Recall\n",
        "metrics = [\"Accuracy\", \"AUC\", \"Precision\", \"Recall\"]\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "results_df.set_index(\"Modelo\")[metrics].plot(kind='bar', ax=ax)\n",
        "plt.title(\"Comparativa de Métricas por Modelo\")\n",
        "plt.ylabel(\"Valor\")\n",
        "plt.ylim(0,1)\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{m_path}/grafica_barras_metricas.png\")\n",
        "plt.show()\n",
        "\n",
        "# Gráfica de líneas del historial de entrenamiento\n",
        "plt.figure(figsize=(10,6))\n",
        "for model_name in histories:\n",
        "    plt.plot(histories[model_name].history['val_accuracy'], label=f'{model_name} (val)')\n",
        "plt.title('Evolución de la Accuracy en Validación')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Matriz de confusión del mejor modelo\n",
        "mejor_modelo = results_df.sort_values('AUC', ascending=False)['Modelo'].iloc[0]\n",
        "cm = confusions[mejor_modelo]\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['<18','18+'], yticklabels=['<18','18+'])\n",
        "plt.title(f\"Matriz de Confusión - {mejor_modelo}\")\n",
        "plt.ylabel('Real')\n",
        "plt.xlabel('Predicho')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TzfTZsXZvDAK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}